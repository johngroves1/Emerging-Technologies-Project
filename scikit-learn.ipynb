{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee7e3ef-040c-4f18-b707-dc9740a86062",
   "metadata": {},
   "source": [
    "<img src=\"./Images/scikit-learn-cover.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9980a3c1-1d3f-4915-8f0f-2de0e0b93640",
   "metadata": {},
   "source": [
    "# Scikit-learn\n",
    "\n",
    "***\n",
    "\n",
    "## Overview of scikit-learn\n",
    "Scikit-learn is a free software machine learning library for the Python programming language. It is build upon NumPy, pandas and Matplotlib. It provides many unsupervised and supervised learning algorithms, the library is focused on modeling data.\n",
    "\n",
    "\n",
    "## Why its used\n",
    "Scikit-learn is the most useful and indept library for machine learning in Python. It provides a lot of efficient tools for machine learning including classification, regression, clustering, model selection and preprocessing.\n",
    "\n",
    "\n",
    "## Contents of notebook\n",
    "...\n",
    "\n",
    "\n",
    "### Algorithms\n",
    "For this module I have been tasked to demonstrate at least three scikit-learn algorithms. The first of which is:\n",
    "- [K-means Algorithm](https://scikit-learn.org/stable/modules/clustering.html#k-means)\n",
    "- [Decision Tree Regression](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html#sphx-glr-auto-examples-tree-plot-tree-regression-py)\n",
    "- [Examples](https://scikit-learn.org/stable/auto_examples/index.html#cluster-examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c201b4d6-d07c-47b3-8882-34e245faec46",
   "metadata": {},
   "source": [
    "# K-means\n",
    "***\n",
    "The KMeans algorithm is an unsupervised clustering machine learning algorithm. A cluster referes to a collection of data points paired together because of certain similarities. This algorithm assumes the number of clusters are pre-defined. The k-means algorithm divides a set of ***N*** samples ***X*** into ***K*** disjoint clusters ***C*** , each described by the mean ***u***  of the samples in the cluster. The means are commonly called the cluster “centroids”; Centroids are initialized by shuffling the dataset and randomly selecting x data points for the centroids. This algorithm calculates and assigns data points to a cluster such that the sum of the squared distance between the data points and centroids are at a minimum.\n",
    "\n",
    "The algorithm is very popular and is used in a wide variety of applications such as market segmentation, data clustering, image segmentation and compression. It is an easy algorithm to understand and implement especially with help from the [scikit library](https://scikit-learn.org/stable/modules/clustering.html#k-means). \n",
    "\n",
    "### How it works\n",
    "The Kmean algorithm works as follows:\n",
    "\n",
    "- **1.** Define the number of clusters *K*\n",
    "- **2.** Initialize centroids by randomly selecting x amount of data points and assigning them to a cluster\n",
    "- **3.** Compute the sum of the squared distance between the data points and centroids\n",
    "     - **3.1** Assign each data point to the closest centroid\n",
    "     - **3.2** Create new centroids by taking the mean value of all the data points assigned to each previous centroid. \n",
    "- **4.** Keep iterating **step 3** until there is little to no significant change to the centroids\n",
    "\n",
    "The K-means algorithm follows the **Expectation-Maximization** approach to solve the problem. An approach where the Expectation step is assigning the data points to the closest cluster and the Maximization step is computing the centroid of each cluster.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## K-Means example: Color Quantization\n",
    "Below I will demonstrate an example of implementing the K-means algorithm to perform a pixel-wise Vector Quantization of an image of a flower. Reducing the number of colours required to display the image from 96,615 unique colours to 64, while preserving the quality of the image. Every pixel is a 3 dimensional vector with Red, Green and Blue components. The image itself is 427 pixels by 640 pixels, so the total amount of vectors are 273,280. The algorithm is ran on these colour vectors and will specify 64 clusters. The result shows how the image is reduced to only 64 colours, some information is lost but the overall quality of the photo remains true. \n",
    "\n",
    "For comparison, a quantized image useing a random selection of colours is shown.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27160f21-4150-454a-a6a8-4f3116a960ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle\n",
    "from time import time\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f18397-fa9a-46cd-8987-1edda30eeb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined number of clusters\n",
    "n_colors = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b90ba713-2f65-4301-8901-28c380b50bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the flower photo\n",
    "flower_img = load_sample_image('flower.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e415b6c-a1e0-4588-8cb2-4709dcc953e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_img.dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4eca8-22e2-4b4c-b199-c9b09a5fa42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# 255 is important so that plt.imshow behaves works well on float data (need to\n",
    "# be in the range [0-1])\n",
    "flower_img = np.array(flower_img, dtype=np.float64) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf0a83-bdbe-4269-bd90-02fbbda9ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Image and transform to a 2D numpy array.\n",
    "w, h, d = original_shape = tuple(flower_img.shape)\n",
    "assert d == 3\n",
    "image_array = np.reshape(flower_img, (w * h, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea4b258-7bc6-4c7a-bec3-bd2681c00aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize centroids by randomly selecting x amount of data points and assigning them to the image_array_sample\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time()\n",
    "image_array_sample = shuffle(image_array, random_state=0, n_samples=1_000)\n",
    "kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9327dbb-f8a8-4c71-b159-29579fc0eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels for all points\n",
    "# Then using the Kmeans predict method, iterates through each data point until there is no change to the clusters\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time()\n",
    "labels = kmeans.predict(image_array)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e42fd-7487-4e1f-995a-d2fdd5f3c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_random = shuffle(image_array, random_state=0, n_samples=n_colors)\n",
    "print(\"Predicting color indices on the full image (random)\")\n",
    "t0 = time()\n",
    "labels_random = pairwise_distances_argmin(codebook_random, image_array, axis=0)\n",
    "print(f\"done in {time() - t0:0.3f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52511c9-07e5-49c5-8b4d-673965c355ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_image(codebook, labels, w, h):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    return codebook[labels].reshape(w, h, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea2fde7-8b91-4ae5-a1c1-1354e555505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all results, alongside original image\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original image (96,615 colors)\")\n",
    "plt.imshow(flower_img)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, K-Means)\")\n",
    "plt.imshow(recreate_image(kmeans.cluster_centers_, labels, w, h))\n",
    "\n",
    "plt.figure(3)\n",
    "plt.clf()\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Quantized image ({n_colors} colors, Random)\")\n",
    "plt.imshow(recreate_image(codebook_random, labels_random, w, h))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c638c7-f8dd-43e1-aa1c-12c676f241ff",
   "metadata": {},
   "source": [
    "# Decision Tree Regression\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a77816-85d4-4201-9c89-bbaf6e7a6120",
   "metadata": {},
   "source": [
    "[Breast Cancer dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d31b5-e457-4989-b9d6-0738bf256981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723484d7-69d1-4d74-aca5-c457b1b951d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard plot size.\n",
    "plt.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a613a-9991-40ae-83e0-9ec7c1f9ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard colour scheme.\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55276786-da2f-46e7-be2e-cc22f2f82b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "df = pd.read_csv(\"breast-cancer-wisconsin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44d8c7-f7ae-4e08-872f-e3b568c990c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ed1be-25e9-48b1-b507-dab42cc932f0",
   "metadata": {},
   "source": [
    "###  Attribute Domain\n",
    "***\n",
    "1) ID number\n",
    "2) Diagnosis (M = malignant, B = benign)\n",
    "3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "\ta) radius (mean of distances from center to points on the perimeter)\n",
    "\tb) texture (standard deviation of gray-scale values)\n",
    "\tc) perimeter\n",
    "\td) area\n",
    "\te) smoothness (local variation in radius lengths)\n",
    "\tf) compactness (perimeter^2 / area - 1.0)\n",
    "\tg) concavity (severity of concave portions of the contour)\n",
    "\th) concave points (number of concave portions of the contour)\n",
    "\ti) symmetry \n",
    "\tj) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "Note each real-value has a mean, standard error and worst value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a73605-d894-4fe8-af44-330db49fe982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Missing Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58af7bd-0f60-4d4f-ad57-b685b45d92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of empty data column with missing values\n",
    "df = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c81d95-4dc4-4224-90c3-e2ef05bcef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows and columns in the data set\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b23058-d815-47a1-84d2-168e7c3b8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking the values of data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b264cf3-eb5d-468a-beef-d6f7fa2713c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the Diagnosis values with 1 = Malignant and 0 = Benign\n",
    "df.diagnosis.replace(('M', 'B'),(1,0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef3b3f-daac-4abb-b88e-692ad773ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset with diagnosis values replaced and missing values dropped\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa5eb9-e220-47fe-824d-f86fbaf48d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33402861-fd0b-4a26-a08a-6249546a91cb",
   "metadata": {},
   "source": [
    "# Data Visualisation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219b522-4f84-4942-ba17-f7821d8246a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Benign or Malignant breast tumour\n",
    "sns.countplot(df['diagnosis'], label='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebeaa85-4a5e-48de-b82f-e8383c524a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of data in correlation to diagnosis values\n",
    "sns.pairplot(df.iloc[:,1:12], hue='diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df52442-74bd-4944-98cc-72e9bb72ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a heatmap to plot all the data effects against each other\n",
    "f, ax = plt.subplots(figsize = (25, 10))\n",
    "sns.heatmap(df.iloc[:,1:12].corr(), annot = True, fmt= '.0%', linewidth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a87606-b98b-46cd-beeb-d90d41808edd",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357f9b3-06fc-4ff1-841c-b6915704b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "# X being all the relevant features that determines if the patient has malignant or benign cancer\n",
    "X = df.iloc[:,2:31].values\n",
    "# y has the diagnosis whether the patient has malginant or benign cancer\n",
    "y = df.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4c484-1d10-472f-bb7a-83ea211a18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size =0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502488c9-6a15-4e32-877e-1dd4edab8ceb",
   "metadata": {},
   "source": [
    "##  Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8492f215-ed64-4e05-90a1-e6297cc89470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Testing regression with different depths\n",
    "regr_1 = DecisionTreeRegressor(random_state = 0, max_depth = 1)\n",
    "regr_2 = DecisionTreeRegressor(random_state = 0, max_depth = 2)\n",
    "regr_3 = DecisionTreeRegressor(random_state = 0, max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4bb2b-11ec-46c3-9975-0d78f0a2e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model to the data\n",
    "regr_1.fit(X, y)\n",
    "regr_2.fit(X, y)\n",
    "regr_3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81848a0a-4d9e-497f-ab08-00ed855b2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction data \n",
    "pred_1 = regr_1.predict(X_test)\n",
    "pred_2 = regr_2.predict(X_test)\n",
    "pred_3 = regr_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd4fe6-60cb-4163-8360-b5328c5b30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting prediction and original data\n",
    "plt.subplots(figsize = (25, 5))\n",
    "\n",
    "plt.plot(Y_test, label = 'data', linewidth = 5, color = 'black')\n",
    "plt.plot(pred_1, label = 'prediction1', linewidth = 1.5, color = 'red')\n",
    "plt.plot(pred_2, label = 'prediction2', linewidth = 1.5, color = 'yellowgreen')\n",
    "plt.plot(pred_3, label = 'prediction3', linewidth = .5, color = 'cyan')\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18efb9a-065b-44c8-8a1d-de9f22c04a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the accurary of each prediction\n",
    "print('Decision Tree Regression Accuracy with depth of 1:', regr_1.score(X_test, Y_test))\n",
    "print('Decision Tree Regression Accuracy with depth of 2:', regr_2.score(X_test,Y_test))\n",
    "print('Decision Tree Regression Accuracy with depth of 5:', regr_3.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10115bc9-0798-46b3-a285-44e7f5e9e46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d94710f6-552c-4782-88de-2bb2312d7aff",
   "metadata": {},
   "source": [
    "***\n",
    "[car data set](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a3134-3ef0-4c9b-9bd4-b91b4feeb9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebd358-1c5a-4bd7-bded-4e7d53597133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334e4bf-b81a-4e3f-96fe-ca78b7e732f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
